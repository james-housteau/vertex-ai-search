# üî¥ URGENT: Enable LLM Add-on to Get Real Benchmarks

## Option 1: Create a Chat App (RECOMMENDED)

### Step 1: Go to Apps Section
```
https://console.cloud.google.com/gen-ai/builder/apps?project=admin-workstation
```

### Step 2: Click "+ CREATE APP"

### Step 3: Configure:
- **App type**: Chat
- **App name**: cox-benchmark-chat
- **Select your data**:
  - ‚úÖ Check "nq-chat-benchmark"
- **Company name**: Capgemini
- **Agent name**: Cox Benchmark Bot

### Step 4: Click "Continue"

### Step 5: In "Configurations":
- **Select generative AI model**:
  - Choose: "Gemini 1.5 Flash 002" (fastest)
  - Or: "Gemini 1.5 Pro 002" (best quality)
- **Enterprise features**:
  - ‚úÖ Enable grounding
  - ‚úÖ Enable summarization

### Step 6: Click "Create"

## Option 2: Update Existing Datastore

### If Option 1 doesn't work, try:

1. Go to: https://console.cloud.google.com/gen-ai/builder/data-stores
2. Click on `nq-chat-benchmark`
3. Go to "Configuration" tab
4. Look for "Advanced features" or "Add-ons"
5. Enable "Large Language Model" or "Conversational Search"

## Option 3: Use Different Project

If your `admin-workstation` project doesn't have billing/quota for LLM:

1. Switch to a Capgemini project with LLM enabled
2. Create datastore there
3. Import the same documents
4. Run benchmarks

## What Success Looks Like:

After enabling, when you run the test:

```bash
poetry run python ../test_real_chat.py
```

You should see:
```
‚úÖ SUCCESS
‚è±Ô∏è Response time: 1847.3ms
üí¨ Answer: To reset your modem, unplug the power cable...
```

## Billing Impact:

- First 1,000 queries: ~$1.25 (Flash) or ~$2.50 (Pro)
- Monthly with 10K queries: ~$12.50-$25
- This is REQUIRED to benchmark Cox's Oliver service

## Still Getting Errors?

Check:
1. Is billing enabled on project `admin-workstation`?
2. Do you have "Vertex AI Administrator" role?
3. Is there a quota limit on LLM queries?

Contact your GCP admin if needed.
